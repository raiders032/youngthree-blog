## 1 S3

- Amazon Simple Storage Service(Amazon S3)는 인터넷 스토리지 서비스로, 안전하고 내구성이 높으며 전 세계 어디서나 데이터를 저장하고 검색할 수 있게 해줍니다.
- Amazon S3는 "무한히 확장 가능한" 스토리지로 알려져 있습니다.
- 사용하기 쉬운 관리 기능을 통해 어느 규모에서나 데이터를 저장하고 제어할 수 있으며, 애플리케이션에 필요한 양만큼만 비용을 지불하면 됩니다.
- Amazon S3는 높은 확장성, 데이터 가용성, 보안 및 성능을 제공하므로, 기업과 개발자는 웹사이트, 모바일 애플리케이션, 백업 및 복원, 아카이브, 엔터프라이즈 애플리케이션, IoT 기기, 빅 데이터 분석 등 다양한 사용 사례에서 S3를 사용할 수 있습니다.



## 2 S3 구성 요소

- Amazon S3의 구성 요소들은 데이터 저장과 관리에 중요한 역할을 합니다.



### 2.1 버킷

- 버킷은 S3에서 데이터를 저장하는 기본 컨테이너입니다.
- 각 버킷은 고유한 이름을 가져야 하며, 전 세계적으로 고유해야 합니다.
	- 버킷 이름은 전 세계적으로 고유해야 하며, 모든 지역과 모든 계정에서 유일해야 합니다.
- 버킷은 객체 데이터를 저장하고, 버킷에 대한 권한을 설정하고, 객체의 생명 주기를 관리하는 데 사용됩니다.
- 버킷은 지역 Region에서 정의됩니다.
	- S3는 글로벌 서비스처럼 보이지만, 버킷은 특정 지역에 생성됩니다.



### 2.2 객체

- 객체는 S3 버킷에 저장되는 기본 데이터 단위입니다.
- 각 객체는 데이터, 메타데이터 및 키(고유 식별자)로 구성됩니다.
- 객체는 파일 크기에 관계없이 저장할 수 있으며, 메타데이터를 통해 추가 정보를 저장할 수 있습니다.
- 메타데이터: 시스템 또는 사용자 메타데이터의 텍스트 키/값 쌍 목록입니다.
- 태그: 최대 10개의 유니코드 키/값 쌍 - 보안 및 라이프사이클 관리에 유용합니다.
- 버전 ID: 버전 관리가 활성화된 경우, 객체의 버전 ID를 가집니다.



**객체 키**

- 객체 키는 버킷 내에서 객체를 고유하게 식별하는 문자열입니다.
- 구조: `prefix + object_name` 예: `my_folder/another_folder/my_file.txt`
    - 접두사 (prefix): `my_folder/another_folder/`
    - 객체 이름 (object_name): `my_file.txt`
- S3에는 실제로 폴더 구조가 없지만, 키에 '/' 문자를 사용하여 폴더 구조를 시뮬레이션할 수 있습니다.
	- 버킷 내에는 "디렉토리" 개념이 없습니다(하지만 UI에서는 그렇게 보일 수 있습니다).
- 버킷과 키의 관계
    - 버킷은 S3의 최상위 컨테이너입니다.
    - 객체 키는 특정 버킷 내에서 객체를 식별하는 고유한 식별자입니다.
- 전체 S3 객체 주소
    - 완전한 S3 객체 주소는 버킷 이름과 객체 키를 조합하여 만들어집니다.
    - 형식: https://[버킷이름].s3.amazonaws.com/[객체키]
- 예시:
    - 버킷 이름: "my-awesome-bucket"
    - 객체 키: "uploads/2023/08/22/image.jpg"
    - 전체 S3 주소: [https://my-awesome-bucket.s3.amazonaws.com/uploads/2023/08/22/image.jpg](https://my-awesome-bucket.s3.amazonaws.com/uploads/2023/08/22/image.jpg)



**객체 값**

- 객체 값은 본문의 내용입니다
- 최대 객체 크기는 5TB(5000GB)입니다.
-  5GB 이상의 데이터를 업로드할 경우, "멀티파트 업로드"를 사용해야 합니다.



## 3 Performance

### 3.1 기본적인 성능

- Amazon S3는 자동으로 높은 요청 속도로 확장되며, 대기 시간은 100-200ms 정도입니다.
- 애플리케이션은 버킷 내 prefix 당 초당 최소 3,500개의 PUT/COPY/POST/DELETE 요청 또는 5,500개의 GET/HEAD 요청을 처리할 수 있습니다.
- **Prefix(접두사)**
	- 객체 키의 경로 부분으로, 객체를 그룹화하는 데 사용됩니다. 
	- 예를 들어 `s3://my-bucket/folder1/sub1/file.txt`에서 `folder1/sub1/`이 접두사입니다. 
	- 접두사는 버킷 이름과 파일 이름 사이의 경로를 의미합니다. 
	- 이를 통해 S3는 객체를 논리적으로 그룹화하고, 성능을 최적화할 수 있습니다.
- 버킷 내 prefix의 수에는 제한이 없습니다.
- 예시 (객체 경로 => prefix):
	  - `bucket/folder1/sub1/file` => `/folder1/sub1/`
	  - `bucket/folder1/sub2/file` => `/folder1/sub2/`
	  - `bucket/1/file` => `/1/`
	  - `bucket/2/file` => `/2/`
- 모든 prefix에 대해 읽기 요청을 고르게 분산시키면, 초당 22,000개의 GET 및 HEAD 요청을 처리할 수 있습니다.



### 3.2 multipart upload

- [레퍼런스](https://docs.aws.amazon.com/AmazonS3/latest/userguide/mpuoverview.html)
- Multipart 업로드는 단일 객체를 여러 부분으로 분할하여 업로드할 수 있게 합니다.
- 각 부분은 객체 데이터의 연속적인 구간입니다.
- 이러한 객체의 부분들은 독립적으로, 그리고 순서에 상관없이 업로드할 수 있습니다.
- 어떤 부분의 전송에 실패하더라도 다른 부분에 영향을 주지 않고 해당 부분을 다시 전송할 수 있습니다.
- 객체의 모든 부분이 업로드되면, Amazon S3는 이러한 부분들을 조립하여 객체를 생성합니다.
- 객체 크기가 100 MB에 도달하면, 객체를 한 번에 업로드하는 대신 multipart 업로드를 사용하는 것이 권장됩니다.



**미완료 업로드 관리**

- S3 수명 주기 정책을 사용하여 미완료된 업로드의 오래된 부분을 자동으로 삭제할 수 있습니다.
- 예를 들어, 네트워크 중단으로 인해 미완료된 업로드의 부분을 x일 후에 자동 삭제하도록 설정할 수 있습니다.



**장점**

- 처리량 향상
	- 객체를 여러 부분들로 나누고 동시에 업로드하여 처리량을 향상시킬 수 있다.
- 네트워크 문제에대해 빠른 복구
	- 네트워크 오류로 인해 실패한 부분만 다시 시작하면 되기 때문에 네트워크 오류로 인한 영향을 최소화한다.
- 최종 객체 크기를 알기 전에 업로드 시작
	- 객체를 생성하는 동안 객체를 업로드할 수 있다.



### 3.3 S3 Transfer Acceleration

![[Pasted image 20231017201344.png]]

- [레퍼런스: Amazon S3 Transfer Acceleration](https://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html)
- **Amazon S3 Transfer Acceleration**은 Amazon S3 서비스의 기능으로, 전 세계 어디서나 대용량 데이터를 Amazon S3로 빠르게 전송할 수 있게 해줍니다.
- **데이터 전송 속도 향상**: 이 기능은 Amazon CloudFront의 글로벌 엣지 위치 네트워크를 활용하여 사용자와 S3 버킷 간의 데이터를 빠르게 전송합니다. 엣지 위치는 사용자의 지리적 위치에 가장 가까운 네트워크 지점이며, 데이터를 Amazon의 전용 네트워크를 통해 S3 버킷으로 전송하여 속도를 높입니다.
- **업로드와 다운로드 모두 지원**: S3 Transfer Acceleration은 데이터의 업로드뿐만 아니라 다운로드 속도도 향상시킵니다. 이를 통해 사용자 경험을 향상시키고, 대규모 데이터 전송을 보다 효율적으로 수행할 수 있습니다.
- **호환성과 비용**: Transfer Acceleration 사용에는 추가 비용이 발생하며, 전송된 데이터의 양과 사용된 엣지 로케이션에 따라 달라집니다. 일부 S3 기능과는 호환되지 않을 수 있으므로 사용하기 전에 호환성을 확인해야 합니다.

 
 
**작동 원리**

1. **활성화**: 사용자는 Amazon S3 버킷에 대해 Transfer Acceleration을 활성화해야 합니다. 활성화되면, Amazon S3는 전 세계의 엣지 로케이션으로 데이터를 전송하는 데 사용할 수 있는 특별한 도메인 이름을 제공합니다.
2. **데이터 전송**: 사용자가 대용량 파일이나 데이터 세트를 S3 버킷으로 업로드할 때, 이 특별한 도메인을 통해 데이터를 전송합니다. 사용자의 데이터는 가장 가까운 엣지 로케이션으로 먼저 전송되고, 그 후 Amazon의 백본 네트워크를 통해 해당 S3 버킷으로 전송됩니다.
3. **속도 향상**: 이 과정을 통해, 데이터는 인터넷상에서 발생할 수 있는 다양한 지연 시간과 병목 현상을 피해 더 빠르게 전송됩니다. 특히 지리적으로 S3 버킷과 멀리 떨어져 있는 사용자는 전송 속도의 상당한 향상을 경험할 수 있습니다.
4. **측정 및 분석**: Amazon S3 Transfer Acceleration 상태 확인 도구를 사용하여, Transfer Acceleration이 활성화된 후 데이터 전송 속도가 얼마나 향상되었는지 측정할 수 있습니다.


### 3.4 S3 Byte-Range Fetches

- GET 요청 시 특정 바이트 범위를 요청하여 병렬로 작업을 수행할 수 있습니다.
- 이는 실패 시 더 나은 복원력을 제공하며 다운로드 속도를 높이는 데 사용할 수 있습니다.
- 파일의 일부 데이터만 필요한 경우, 예를 들어 파일의 헤더 부분만 가져오고자 할 때 유용합니다.
- 여러 요청을 병렬로 수행할 수 있습니다.



## 4 S3 File Gateway

- Amazon S3 File Gateway는 온프레미스 환경과 AWS 클라우드 간의 데이터 이동을 간소화하는 서비스입니다.
- 이 서비스는 기업이 기존의 파일 기반 애플리케이션과 작업 흐름을 AWS로 확장할 수 있도록 지원합니다.



### 4.1 주요 기능 및 이점

- 온프레미스 파일 서버와의 원활한 통합
	- S3 File Gateway는 온프레미스 파일 서버의 기능을 클라우드로 확장합니다. 
	- 온프레미스 사용자가 네트워크 파일 시스템(NFS) 및 서버 메시지 블록(SMB) 프로토콜을 통해 클라우드 스토리지에 접근할 수 있게 하여, 사용자는 마치 로컬 파일 서버에 있는 파일을 다루는 것처럼 클라우드에 저장된 파일을 다룰 수 있습니다.
- 안전하고 신뢰할 수 있는 스토리지
	- S3 File Gateway를 통해 저장된 파일은 Amazon S3 버킷에 안전하게 저장됩니다. 
	- Amazon S3는 높은 내구성과 가용성을 제공하여 데이터가 필요할 때 보호되고 접근 가능하도록 보장합니다.
- 비용 효율적인 스토리지 관리
	- s3 File Gateway를 사용하면 데이터는 S3 버킷에 저장되고 사용 패턴에 따라 다양한 S3 스토리지 클래스로 자동 전환될 수 있습니다. 
	- 이를 통해 기업은 S3 Standard, S3 Standard-IA(비정기 접근), S3 Glacier 등 다양한 스토리지 클래스를 활용하여 스토리지 비용을 최적화할 수 있습니다.
- 자동화된 수명 주기 관리
	- S3 File Gateway와 S3 라이프사이클 정책을 결합하면, 오래된 파일을 더 비용 효율적인 스토리지 솔루션으로 자동 이동시킬 수 있습니다. 
	- 예를 들어, 자주 접근하지 않는 파일은 S3 Glacier 또는 S3 Glacier Deep Archive로 이동시켜 스토리지 비용을 크게 절감하면서도 데이터가 컴플라이언스 및 아카이브 목적을 위해 필요할 때 사용할 수 있습니다.
- 간소화된 데이터 백업 및 복구
	- S3 File Gateway는 데이터 백업 및 복구 과정을 간소화합니다.
	- Amazon S3에 백업 데이터를 저장하여 온프레미스 장애로부터 데이터를 보호하고 필요 시 쉽게 복구할 수 있습니다.
- 확장성 및 유연성
	- Amazon S3는 사실상 무한한 저장 용량을 제공하여 온프레미스 인프라의 제한 없이 스토리지 요구 사항을 확장할 수 있습니다. 
	- 이를 통해 기업은 증가하는 데이터 볼륨을 효율적으로 처리할 수 있습니다.



## 5 S3 데이터 보호 및 관리

### 5.1 버전 관리(Versioning)

- Amazon S3의 버전 관리를 활성화하면, 객체의 여러 버전을 저장하여 실수로 삭제되거나 덮어쓴 데이터를 복구할 수 있습니다.
- 이는 중요한 데이터를 보호하는 데 매우 유용하며, 이전 버전으로 쉽게 복원할 수 있습니다.
- 파일을 버전 관리할 수 있으며, 버킷 수준에서 활성화됩니다.
- [[AWS/S3/Versioning/Versioning]] 참고



### 5.2 MFA Delete

- 다단계 인증(Multi-Factor Authentication)을 사용하여 삭제 작업을 보호합니다.
- MFA Delete를 활성화하면, 추가적인 인증 과정을 거쳐야만 객체를 삭제할 수 있어 실수나 악의적인 삭제를 방지할 수 있습니다.
- MFA는 사용자가 중요한 작업을 수행하기 전에 장치(일반적으로 모바일 폰 또는 하드웨어)에서 코드를 생성하도록 강제합니다.
- MFA가 필요한 작업
    - 객체 버전을 영구적으로 삭제
    - 버킷의 버전 관리를 중단
- MFA가 필요하지 않은 작업
    - 버전 관리 활성화
    - 삭제된 버전 나열
- MFA Delete를 사용하려면 버킷에 버전 관리가 활성화되어 있어야 합니다.
- 오직 버킷 소유자(루트 계정)만 MFA Delete를 활성화하거나 비활성화할 수 있습니다.



## 6 Requester Pays 버킷

- **Requester Pays** 기능을 사용하면, 데이터를 요청하는 쪽에서 데이터 전송 비용을 부담하게 할 수 있습니다.
- 일반적으로 버킷 소유자는 버킷과 관련된 모든 Amazon S3 저장 및 데이터 전송 비용을 부담합니다.
- 그러나 Requester Pays 버킷을 사용하면, 데이터 요청자가 요청 비용과 버킷에서 데이터를 다운로드하는 비용을 부담하게 됩니다.
- 이 기능을 활성화하면, 버킷 소유자는 데이터 저장 비용을 부담하고, 데이터 요청자는 데이터 전송 비용을 부담하게 됩니다.
- Requester Pays는 데이터를 제공하는 회사가 데이터 전송 비용을 절감하는 데 유용합니다.
- 이를 통해 데이터 공유 시 발생하는 비용을 효율적으로 분담할 수 있습니다.
- Requester Pays 버킷을 사용할 때 요청자는 AWS에 인증되어야 하며, 익명 요청자는 사용할 수 없습니다.



## 7 Amazon S3 Replication

- Amazon S3 Replication은 데이터를 여러 버킷에 복제하여 데이터 가용성을 높이고, 규정 준수를 보장하며, 지연 시간을 줄이는 데 사용됩니다.
- S3 복제는 Cross-Region Replication (CRR)과 Same-Region Replication (SRR)의 두 가지 유형이 있습니다.
- 복제를 설정하기 위해서는 원본 및 대상 버킷에서 버전 관리를 활성화해야 합니다.
- 복사는 비동기적으로 수행됩니다.
- 새로운 객체만 복제되며, 기존 객체는 S3 Batch Replication을 사용하여 복제할 수 있습니다.
- S3 복제를 위해 적절한 IAM 권한을 부여해야 합니다.
- 복제 설정 시 삭제 마커를 대상 버킷으로 복제할 수 있습니다.
- 버전 ID가 있는 삭제는 복제되지 않아 악의적인 삭제를 방지할 수 있습니다.
- S3 복제에는 "체인 복제"가 적용되지 않습니다.
	- 예를 들어, 버킷 1이 버킷 2로 복제되고, 버킷 2가 버킷 3으로 복제되는 경우, 버킷 1에 생성된 객체는 버킷 3으로 복제되지 않습니다.



### 7.1 Cross-Region Replication (CRR)

- CRR은 다른 AWS 리전 간의 버킷 복제를 가능하게 합니다.
- 주로 규정 준수, 낮은 지연 시간의 액세스, 계정 간 복제와 같은 용도로 사용됩니다.



### 7.2 Same-Region Replication (SRR)

- SRR은 동일한 AWS 리전 내에서 버킷 복제를 가능하게 합니다.
- 로그 집계, 프로덕션과 테스트 계정 간의 실시간 복제 등의 용도로 사용됩니다.



## 8 S3 Select & Glacier Select

- **S3 Select**와 **Glacier Select**는 Amazon S3 또는 Amazon S3 Glacier에 저장된 객체에서 필요한 데이터 부분만을 검색할 수 있는 기능입니다.
- 서버 측 필터링을 통해 SQL 같은 쿼리를 사용하여 객체의 특정 행과 열을 선택할 수 있습니다.
- 이는 네트워크 전송량을 줄이고, 클라이언트 측의 CPU 비용을 절감하는 데 도움을 줍니다.



### 8.1 주요 기능

- **SQL 쿼리 사용**: SQL과 유사한 쿼리를 사용하여 객체에서 필요한 데이터 부분만 선택할 수 있습니다. 예를 들어, 특정 조건을 만족하는 행이나 열만 선택하여 가져올 수 있습니다.
- **서버 측 필터링**: 데이터 필터링을 서버 측에서 수행하여 필요한 데이터만 전송함으로써, 네트워크 비용과 데이터 전송 시간을 절감할 수 있습니다.
- **지원되는 포맷**: CSV, JSON, Parquet 형식을 포함한 다양한 데이터 포맷을 지원합니다.



### 8.2 장점

- **네트워크 전송 감소**: 전체 객체를 다운로드하지 않고 필요한 데이터 부분만 전송받을 수 있어 네트워크 트래픽을 줄일 수 있습니다.
- **클라이언트 측 처리 비용 절감**: 데이터 필터링을 서버 측에서 수행하므로, 클라이언트 측에서 데이터 처리에 드는 CPU 및 메모리 사용량을 줄일 수 있습니다.
- **비용 효율성**: 전송되는 데이터 양이 줄어들어 데이터 전송 비용을 절감할 수 있습니다.



### 8.3 작동 원리

1. **데이터 저장**: S3 또는 Glacier에 데이터가 저장됩니다. 데이터는 주로 CSV, JSON, Parquet 형식으로 저장됩니다.
2. **SQL 쿼리 작성**: 필요한 데이터를 선택하는 SQL 쿼리를 작성합니다.
3. **쿼리 실행**: S3 Select 또는 Glacier Select API를 통해 쿼리를 실행합니다.
4. **필터링된 데이터 전송**: 쿼리 결과로 필터링된 데이터만 전송받습니다.



### 8.4 사용 예시

- **로그 분석**: 전체 로그 파일을 다운로드하지 않고 특정 시간 범위 내의 로그 항목만 선택하여 분석할 수 있습니다.
- **데이터 분석**: 대규모 데이터 세트에서 특정 조건에 맞는 데이터만 선택하여 분석 작업을 수행할 수 있습니다.
- **빅 데이터 처리**: 데이터 처리 작업 전에 필요한 데이터 부분만 선택하여 처리 효율을 높일 수 있습니다.



## 9 S3 User-Defined Object Metadata & S3 Object Tags

- Amazon S3에서 객체를 업로드할 때 사용자 정의 메타데이터와 객체 태그를 사용하여 객체를 더 잘 관리하고 분류할 수 있습니다.



### 9.1 S3 User-Defined Object Metadata

- **메타데이터 할당**: 객체를 업로드할 때 메타데이터를 할당할 수 있습니다.
- **이름-값 (키-값) 쌍**: 사용자 정의 메타데이터는 이름-값 쌍으로 지정됩니다.
- **명명 규칙**: 사용자 정의 메타데이터 이름은 "x-amz-meta-"로 시작해야 합니다.
- **소문자 저장**: Amazon S3는 사용자 정의 메타데이터 키를 소문자로 저장합니다.
- **메타데이터 검색**: 객체를 검색할 때 메타데이터도 함께 검색할 수 있습니다.



### 9.2 S3 Object Tags

- **키-값 쌍**: Amazon S3의 객체에 대한 키-값 쌍입니다.
- **세분화된 권한 관리**: 특정 태그를 가진 객체에만 접근 권한을 부여할 때 유용합니다.
- **분석 목적**: S3 Analytics를 사용하여 태그별로 객체를 그룹화할 수 있어 분석에 유용합니다.
- **검색 제한**: 객체 메타데이터나 객체 태그를 직접 검색할 수는 없습니다.
- **외부 DB 사용**: 대신, DynamoDB와 같은 외부 데이터베이스를 검색 인덱스로 사용해야 합니다.



### 9.3 사용 예시

- **권한 관리**: 예를 들어, "x-amz-meta-department" 메타데이터를 사용하여 특정 부서만 해당 객체에 접근할 수 있도록 설정할 수 있습니다.
- **분석 및 분류**: "project"와 같은 태그를 사용하여 프로젝트별로 객체를 분류하고, S3 Analytics를 통해 분석할 수 있습니다.
- **검색 인덱스**: 객체 메타데이터와 태그를 인덱싱하기 위해 DynamoDB를 사용하여 객체를 효율적으로 검색할 수 있습니다.



**참고 자료**

- [Amazon S3 공식 문서](https://docs.aws.amazon.com/s3/index.html)
- [Amazon S3 Transfer Acceleration](https://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html)
- [Amazon S3 Object Lock](https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock.html)
- [Amazon S3 라이프사이클 관리](https://docs.aws.amazon.com/AmazonS3/latest/userguide/lifecycle-transition-general-considerations.html)
- [Long-term data storage using S3 Glacier storage classes](https://docs.aws.amazon.com/AmazonS3/latest/userguide/glacier-storage-classes.html)